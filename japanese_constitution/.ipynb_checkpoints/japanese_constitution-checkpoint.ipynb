{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c6adc1a-9ab4-4caf-b344-d5fdda1ed983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "transformers 4.24.0 requires tokenizers!=0.11.3,<0.14,>=0.11.1, but you have tokenizers 0.20.1 which is incompatible.\n",
      "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai langchain-community faiss-cpu -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b593f51-a290-4e93-9297-b80087020ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e685d518-8367-4514-b53c-2c747946b2e7",
   "metadata": {},
   "source": [
    "### 1. Load and Split Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd934707-1e06-43ab-8faf-264b57c7be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\n",
    "    \"nihonkokukenpou.pdf\",\n",
    ")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"。\", \"!\", \"?\", \"、\", \" \", \"\"],\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "docs = loader.load_and_split(text_splitter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2ef466-106c-48a4-ac61-080d11f536b6",
   "metadata": {},
   "source": [
    "### 2. Embed Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b53e2231-637d-418c-984b-023e9780b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34836060-b970-489b-a00b-df10002b43ee",
   "metadata": {},
   "source": [
    "### 3. Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8cfa0854-a1f6-46d2-9f3f-a62f465f70cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vector_store = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f695e2a-d4ed-49b3-82cf-cfcf30ef1c50",
   "metadata": {},
   "source": [
    "### 4. Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6b50876e-d754-418e-9cc2-4cc5a3a3e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8d3e8e-cf75-48ed-af62-597d6e96e783",
   "metadata": {},
   "source": [
    "### 5. Question and Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "624f4f21-9758-44c0-b365-87e2deb50db4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Prompt must accept context as an input variable. Received prompt with input variables: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 23\u001b[0m\n\u001b[1;32m     13\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse the given context to answer the question. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124mIf you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt know the answer, say honestly that you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt know the answer.\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124mMake sure to answer in the \u001b[39m\u001b[38;5;132;01m{language}\u001b[39;00m\u001b[38;5;124m language.\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124mcontext:\u001b[39m\u001b[38;5;132;01m{context}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m template \u001b[38;5;241m=\u001b[39m ChatPromptTemplate([\n\u001b[1;32m     19\u001b[0m     SystemMessage(content\u001b[38;5;241m=\u001b[39msystem_prompt),\n\u001b[1;32m     20\u001b[0m     HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m ], input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m combine_docs_chain \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_stuff_documents_chain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStrOutputParser\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m rag_chain \u001b[38;5;241m=\u001b[39m create_retrieval_chain(retriever, combine_docs_chain)\n\u001b[1;32m     30\u001b[0m rag_chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJapanese\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan Japan possess Nuclear weapons\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain/chains/combine_documents/stuff.py:79\u001b[0m, in \u001b[0;36mcreate_stuff_documents_chain\u001b[0;34m(llm, prompt, output_parser, document_prompt, document_separator, document_variable_name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_stuff_documents_chain\u001b[39m(\n\u001b[1;32m     25\u001b[0m     llm: LanguageModelLike,\n\u001b[1;32m     26\u001b[0m     prompt: BasePromptTemplate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     document_variable_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m DOCUMENTS_KEY,\n\u001b[1;32m     32\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Runnable[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Any]:\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chain for passing a list of Documents to a model.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m            chain.invoke({\"context\": docs})\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     \u001b[43m_validate_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument_variable_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     _document_prompt \u001b[38;5;241m=\u001b[39m document_prompt \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_DOCUMENT_PROMPT\n\u001b[1;32m     81\u001b[0m     _output_parser \u001b[38;5;241m=\u001b[39m output_parser \u001b[38;5;129;01mor\u001b[39;00m StrOutputParser()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py:27\u001b[0m, in \u001b[0;36m_validate_prompt\u001b[0;34m(prompt, document_variable_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_prompt\u001b[39m(prompt: BasePromptTemplate, document_variable_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m document_variable_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m prompt\u001b[38;5;241m.\u001b[39minput_variables:\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt must accept \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocument_variable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as an input variable. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived prompt with input variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;241m.\u001b[39minput_variables\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Prompt must accept context as an input variable. Received prompt with input variables: []"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "\n",
    "system_prompt = \"Use the given context to answer the question. \\\n",
    "If you don't know the answer, say honestly that you don't know the answer.\\\n",
    "Make sure to answer in the {language} language.\\\n",
    "context:{context}\"\n",
    "\n",
    "template = ChatPromptTemplate([\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(content=\"{question}\")\n",
    "], input_variables=[\"context\", \"language\", \"question\"])\n",
    "\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=template,\n",
    "    output_parser=StrOutputParser\n",
    ")\n",
    "rag_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "\n",
    "rag_chain.invoke({\"language\":\"Japanese\", \"question\":\"Can Japan possess Nuclear weapons\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028efec9-45b1-454b-ad9c-6373832c13b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
